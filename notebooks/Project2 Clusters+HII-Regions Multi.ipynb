{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cluster and HII-regions Multi <a class=\"tocSkip\">\n",
    "\n",
    "the aim of this notebook is to combine the HII-region and cluster catalogues.\n",
    "   \n",
    "This notebook useses multiple galaxies at once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reload modules after they have been modified\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from pnlf.packages import *\n",
    "\n",
    "from pnlf.constants import tab10, single_column, two_column\n",
    "from pnlf.plot import quick_plot\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(stream=sys.stdout,\n",
    "                    #format='(levelname)s %(name)s %(message)s',\n",
    "                    datefmt='%H:%M:%S',\n",
    "                    level=logging.INFO)\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "# first we need to specify the path to the raw data\n",
    "basedir = Path('..')\n",
    "data_ext = Path('a:') #basedir / 'data' / 'raw' \n",
    "\n",
    "sample_table = ascii.read(basedir/'..'/'pnlf'/'data'/'interim'/'sample.txt')\n",
    "sample_table.add_index('name')\n",
    "sample_table['SkyCoord'] = SkyCoord(sample_table['R.A.'],sample_table['Dec.'])\n",
    "sample_table['power_index'] = 2.3\n",
    "sample_table['power_index'][sample_table['AO'].mask]=2.8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hst_sample      = set(['NGC0628','NGC1365','NGC1433', 'NGC1566', 'NGC3351', 'NGC3627', 'NGC4535'])\n",
    "astrosat_sample = set([x.stem.split('_')[0] for x in (data_ext/'Astrosat').iterdir() if x.is_file() and x.suffix=='.fits'])\n",
    "muse_sample     = set(sample_table['name'])\n",
    "complete_sample = hst_sample & astrosat_sample & muse_sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The nebulae catalogue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scalepc = 32\n",
    "\n",
    "# the original catalogue from Francesco\n",
    "with fits.open(basedir / 'data' / 'interim' / 'Nebulae_Catalogue_v2p1.fits') as hdul:\n",
    "    nebulae = Table(hdul[1].data)\n",
    "nebulae['SkyCoord'] = SkyCoord(nebulae['cen_ra']*u.deg,nebulae['cen_dec']*u.deg,frame='icrs')\n",
    "    \n",
    "nebulae.rename_columns(['cen_x','cen_y','cen_ra','cen_dec','region_area',\n",
    "                          'EBV','EBV_ERR','SkyCoord'],\n",
    "                         ['x_neb','y_neb','ra_neb','dec_neb','area_neb',\n",
    "                          'EBV_balmer','EBV_balmer_err','SkyCoord_neb'])\n",
    "    \n",
    "# some additional properties \n",
    "with fits.open(basedir/'data'/'interim'/f'Nebulae_Catalogue_v2p1_dig.fits') as hdul:\n",
    "    dig = Table(hdul[1].data)\n",
    "dig['dig/hii'] = dig['dig_median'] / dig['hii_median']\n",
    "\n",
    "with fits.open(basedir/'data'/'interim'/f'Nebulae_Catalogue_v2p1_fuv.fits') as hdul:\n",
    "    fuv = Table(hdul[1].data)\n",
    "    \n",
    "with fits.open(basedir/'data'/'interim'/f'Nebulae_Catalogue_v2p1_eq.fits') as hdul:\n",
    "    eq_width = Table(hdul[1].data)\n",
    "    \n",
    "nebulae = join(nebulae,fuv,keys=['gal_name','region_ID'])\n",
    "nebulae = join(nebulae,eq_width,keys=['gal_name','region_ID'])\n",
    "nebulae = join(nebulae,dig,keys=['gal_name','region_ID'])\n",
    "\n",
    "# this will rais a few errors that we just ignore\n",
    "with np.errstate(divide='ignore',invalid='ignore'):\n",
    "    nebulae['[SIII]/[SII]'] = np.nan\n",
    "    SII = nebulae['SII6716_FLUX_CORR']+nebulae['SII6730_FLUX_CORR']\n",
    "    SIII = nebulae['SIII6312_FLUX_CORR']+nebulae['SIII9068_FLUX_CORR']\n",
    "    nebulae['[SIII]/[SII]'][SII>0] = SIII[SII>0]/SII[SII>0]\n",
    "    nebulae['HA/FUV'] = nebulae['HA6562_FLUX_CORR']/nebulae['FUV_FLUX_CORR']\n",
    "    \n",
    "    \n",
    "# the nebulae catalogue with additional information\n",
    "folder = basedir/'data'/'map_nebulae_association'\n",
    "\n",
    "lst = []\n",
    "for file in folder.glob(f'*{scalepc}pc_nebulae.fits'):\n",
    "    gal_name = file.stem.split('_')[0]\n",
    "    print(f'reading {gal_name}')\n",
    "    tbl = Table(fits.getdata(file,ext=1))\n",
    "    tbl.add_column(gal_name,name='gal_name',index=0)\n",
    "    name=gal_name.lower()\n",
    "    lst.append(tbl)\n",
    "nebulae_tmp = vstack(lst)\n",
    "\n",
    "nebulae = join(nebulae,nebulae_tmp,keys=['gal_name','region_ID'],join_type='outer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The association catalogue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# those files hold the merged association catalogues\n",
    "with fits.open(basedir/'data'/'interim'/f'phangshst_associations_nuv_ws{scalepc}pc_v1p1.fits') as hdul:\n",
    "    associations = Table(hdul[1].data)\n",
    "    \n",
    "associations['SkyCoord'] = SkyCoord(associations['reg_ra']*u.degree,associations['reg_dec']*u.degree)\n",
    "associations.rename_columns(['reg_ra','reg_dec','reg_x','reg_y',\n",
    "                             'reg_dolflux_Age_MinChiSq','reg_dolflux_Mass_MinChiSq','reg_dolflux_Ebv_MinChiSq',\n",
    "                             'reg_dolflux_Age_MinChiSq_err','reg_dolflux_Mass_MinChiSq_err','reg_dolflux_Ebv_MinChiSq_err',\n",
    "                             'SkyCoord'],\n",
    "                            ['ra_asc','dec_asc','x_asc','y_asc','age','mass',\n",
    "                             'EBV_stars','age_err','mass_err','EBV_stars_err','SkyCoord_asc'])\n",
    "\n",
    "# Halpha measured in the association masks\n",
    "with fits.open(basedir/'data'/'interim'/f'phangshst_associations_nuv_ws32pc_v1p1_Halpha.fits') as hdul:\n",
    "    assoc_Halpha = Table(hdul[1].data)\n",
    "\n",
    "# the association catalogue matched with the nebuale catalogue\n",
    "folder = basedir/'data'/'map_nebulae_association'\n",
    "\n",
    "lst = []\n",
    "for file in folder.glob(f'*{scalepc}pc_associations.fits'):\n",
    "    gal_name = file.stem.split('_')[0]\n",
    "    print(f'reading {gal_name}')\n",
    "    tbl = Table(fits.getdata(file,ext=1))\n",
    "    tbl.add_column(gal_name,name='gal_name',index=0)\n",
    "    lst.append(tbl)\n",
    "assoc_tmp = vstack(lst)\n",
    "\n",
    "\n",
    "# combine both catalogues\n",
    "associations = join(associations,assoc_tmp,keys=['gal_name','assoc_ID'])\n",
    "print(f'{len(associations)} associations in final catalogue')\n",
    "\n",
    "criteria = np.abs(associations['age']-associations['age_16'])>associations['age_err']\n",
    "criteria |= np.abs(associations['age']-associations['age_64'])>associations['age_err']\n",
    "\n",
    "associations['uniform_age'] = ~criteria"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The joined catalogue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can also recreate the table from the association an nebulae catalogues\n",
    "catalogue = join(nebulae[~nebulae['assoc_ID'].mask],associations,keys=['gal_name','assoc_ID','region_ID'])\n",
    "#catalogue['SkyCoord_asc'] = SkyCoord(catalogue['ra_asc'],catalogue['dec_asc'])\n",
    "#catalogue['SkyCoord_neb'] = SkyCoord(catalogue['ra_neb'],catalogue['dec_neb'])\n",
    "catalogue['HA/FUV'] = catalogue['HA6562_FLUX_CORR']/catalogue['FUV_FLUX_CORR']\n",
    "\n",
    "# add dig and calculate galactic radius\n",
    "catalogue['galactic_radius'] = np.nan\n",
    "for gal_name in np.unique(catalogue['gal_name']):\n",
    "    centre = sample_table.loc[gal_name]['SkyCoord']\n",
    "    catalogue['galactic_radius'][catalogue['gal_name']==gal_name] = catalogue[catalogue['gal_name']==gal_name]['SkyCoord_neb'].separation(centre).to(u.arcmin)\n",
    "\n",
    "print(f'{len(catalogue)} objects in final catalogue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# catalogue with Halpha based on association mask\n",
    "catalogue = join(associations,assoc_Halpha,keys=['gal_name','assoc_ID'])\n",
    "catalogue['dig/hii'] = catalogue['dig_median'] / catalogue['hii_median']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'associations: {len(associations)}')\n",
    "print(f'nebulae: {len(nebulae[np.isin(nebulae[\"gal_name\"],list(hst_sample))])}')\n",
    "print(f'match: {len(catalogue)}')\n",
    "print(f'contained: {len(catalogue[catalogue[\"overlap\"]==\"contained\"])}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Table to showcase the sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "astrosat_sample = [x.stem.split('_')[0] for x in (data_ext/'Astrosat').iterdir() if x.is_file() and x.suffix=='.fits']\n",
    "muse_sample     = sample_table['name']\n",
    "hst_sample      = associations['gal_name']\n",
    "sitelle_sample  = ['NGC0628','NGC2835','NGC3351','NGC3627','NGC4535']\n",
    "\n",
    "t = Table({\n",
    "    'Name':muse_sample,\n",
    "    'MUSE':np.isin(muse_sample,muse_sample),\n",
    "    'HST':np.isin(muse_sample,hst_sample),\n",
    "    'Astrosat':np.isin(muse_sample,astrosat_sample),\n",
    "    'Sitelle':np.isin(muse_sample,sitelle_sample)}\n",
    "     )\n",
    "\n",
    "for col in t.columns[1:]:\n",
    "    t[col] = ['\\checkmark' if x else '' for x in t[col] ]\n",
    "ascii.write(t,sys.stdout, Writer = ascii.Latex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search for correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cluster.auxiliary import bin_stat\n",
    "\n",
    "xlim = [0.5,10.5]\n",
    "\n",
    "criteria = (catalogue['mass']>1e3)\n",
    "criteria &= catalogue['uniform_age']\n",
    "#criteria &= (catalogue['overlap']=='contained')\n",
    "tmp = catalogue[criteria]\n",
    "print(len(tmp))\n",
    "\n",
    "x,mean,std = bin_stat(tmp['age'],tmp['eq_width'],xlim)\n",
    "\n",
    "fig,ax=plt.subplots(figsize=(single_column,single_column))\n",
    "\n",
    "ax.scatter(tmp['age'],tmp['eq_width'])\n",
    "ax.errorbar(x,mean,yerr=std,color='black')\n",
    "\n",
    "ax.set(xlim=xlim,ylim=[0,200])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Plot the sample (cutouts)\n",
    "\n",
    "plot all objects in the merged catalogues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from cluster.io import read_associations\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "from cluster.plot import single_cutout\n",
    "\n",
    "\n",
    "criteria = (catalogue['mass']>1e3) \n",
    "#criteria &= ~np.isnan(catalogue['HA/FUV'])\n",
    "criteria &= (catalogue['overlap'] == 'contained')\n",
    "criteria &= (catalogue['age'] > 10)\n",
    "tmp = catalogue[criteria]\n",
    "tmp = tmp\n",
    "\n",
    "print(f'{name}: {len(tmp)} objects')\n",
    "\n",
    "size=10*u.arcsec\n",
    "nrows=5\n",
    "ncols=4\n",
    "filename = basedir/'reports'/f'all_galaxies_{scalepc}_cutouts'\n",
    "\n",
    "    \n",
    "width = 8.27\n",
    "N = len(tmp) \n",
    "Npage = nrows*ncols-1\n",
    "if N%Npage==0:\n",
    "    print('sample size % subplots = 0: no subplot for legend')\n",
    "Npages = int(np.ceil(N/Npage))\n",
    "gal_name = None\n",
    "\n",
    "with PdfPages(filename.with_suffix('.pdf')) as pdf:\n",
    "\n",
    "    for i in range(Npages):\n",
    "        print(f'working on page {i+1} of {Npages}')\n",
    "\n",
    "        sub_sample = tmp[i*Npage:(i+1)*Npage]\n",
    "\n",
    "        fig, axes = plt.subplots(nrows=nrows,ncols=ncols,figsize=(width,width/ncols*nrows))\n",
    "        axes_iter = iter(axes.flatten())\n",
    "\n",
    "        for row in sub_sample:  \n",
    "            \n",
    "            # for a new galaxy we need to read in the masks/images\n",
    "            if row['gal_name'] != gal_name:\n",
    "                \n",
    "                gal_name = row['gal_name']\n",
    "                \n",
    "                # HST image for the background\n",
    "                filename = data_ext / 'HST' / 'filterImages' / f'{gal_name.lower()}_uvis_f275w_exp_drc_sci.fits'\n",
    "                with fits.open(filename) as hdul:\n",
    "                    F275 = NDData(hdul[0].data,\n",
    "                                  mask=hdul[0].data==0,\n",
    "                                  meta=hdul[0].header,\n",
    "                                  wcs=WCS(hdul[0].header))\n",
    "                \n",
    "                # nebulae mask\n",
    "                filename = data_ext / 'MUSE_DR2.1' / 'Nebulae catalogue' /'spatial_masks'/f'{gal_name}_nebulae_mask.fits'\n",
    "                with fits.open(filename) as hdul:\n",
    "                    nebulae_mask = NDData(hdul[0].data.astype(float),meta=hdul[0].header,wcs=WCS(hdul[0].header))\n",
    "                    nebulae_mask.data[nebulae_mask.data==-1] = np.nan\n",
    "                \n",
    "                # association mask\n",
    "                associations_mask = read_associations(folder=data_ext/'HST',\n",
    "                                                      target=gal_name.lower(),\n",
    "                                                      scalepc=scalepc,\n",
    "                                                      data='mask')\n",
    "\n",
    "            \n",
    "            ax = next(axes_iter)\n",
    "            ax = single_cutout(ax,\n",
    "                             position = row['SkyCoord_neb'],\n",
    "                             image = F275,\n",
    "                             mask1 = nebulae_mask,\n",
    "                             mask2 = associations_mask,\n",
    "                             label = f\"{row['gal_name']}: {row['region_ID']:.0f}/{row['assoc_ID']:.0f}\",\n",
    "                             size  = 4*u.arcsecond)\n",
    "\n",
    "        plt.subplots_adjust(wspace=-0.01, hspace=0.05)\n",
    "\n",
    "        # only the last page has subplots that need to be removed\n",
    "        h,l = fig.axes[0].get_legend_handles_labels()\n",
    "        ax = next(axes_iter)\n",
    "        ax.axis('off')\n",
    "        ax.legend(h[::len(h)-1],l[::(len(l)-1)],fontsize=7,loc='center',frameon=False)\n",
    "        t = ax.text(0.07,0.87,'name: region ID/assoc ID', transform=ax.transAxes,color='black',fontsize=8)\n",
    "\n",
    "        if i == int(np.ceil(N/Npage))-1:\n",
    "\n",
    "            for i in range(nrows*ncols-len(sub_sample)-1):\n",
    "                # remove the empty axes at the bottom\n",
    "                ax = next(axes_iter)\n",
    "                ax.axis('off')    \n",
    "\n",
    "        pdf.savefig()  # saves the current figure into a pdf page\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "three color composit with CO emission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from cluster.io import read_associations\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "from reproject import reproject_interp\n",
    "from skimage.measure import find_contours\n",
    "from pnlf.plot import create_RGB\n",
    "\n",
    "'''\n",
    "criteria = (catalogue['mass']>1e3) \n",
    "criteria &= (catalogue['overlap'] == 'contained')\n",
    "#criteria &= (catalogue['age'] > 10)\n",
    "tmp = catalogue[criteria]\n",
    "'''\n",
    "print(f'{len(tmp)} objects')\n",
    "\n",
    "size=5*u.arcsec\n",
    "nrows=5\n",
    "ncols=4\n",
    "filename = basedir/'reports'/f'all_galaxies_{scalepc}_cutouts_rgb_neg_fesc'\n",
    "\n",
    "width = 8.27\n",
    "N = len(tmp) \n",
    "Npage = nrows*ncols-1\n",
    "if N%Npage==0:\n",
    "    print('sample size % subplots = 0: no subplot for legend')\n",
    "Npages = int(np.ceil(N/Npage))\n",
    "gal_name = None\n",
    "\n",
    "with PdfPages(filename.with_suffix('.pdf')) as pdf:\n",
    "\n",
    "    for j in range(Npages):\n",
    "        print(f'working on page {j+1} of {Npages}')\n",
    "\n",
    "        sub_sample = tmp[j*Npage:(j+1)*Npage]\n",
    "\n",
    "        fig, axes = plt.subplots(nrows=nrows,ncols=ncols,figsize=(width,width/ncols*nrows))\n",
    "        axes_iter = iter(axes.flatten())\n",
    "\n",
    "        for row in sub_sample:  \n",
    "            \n",
    "            # for a new galaxy we need to read in the masks/images\n",
    "            if row['gal_name'] != gal_name:\n",
    "                \n",
    "                gal_name = row['gal_name']\n",
    "                print(f'reading files for {gal_name}')\n",
    "                \n",
    "                # HST image for the background\n",
    "                filename = data_ext / 'HST' / 'filterImages' / f'{gal_name.lower()}_uvis_f275w_exp_drc_sci.fits'\n",
    "                with fits.open(filename) as hdul:\n",
    "                    F275 = NDData(hdul[0].data,\n",
    "                                  mask=hdul[0].data==0,\n",
    "                                  meta=hdul[0].header,\n",
    "                                  wcs=WCS(hdul[0].header))\n",
    "                \n",
    "                filename = data_ext / 'MUSE_DR2.1' / 'MUSEDAP' / f'{gal_name}_MAPS.fits'\n",
    "                with fits.open(filename) as hdul:\n",
    "                    Halpha = NDData(data=hdul['HA6562_FLUX'].data,\n",
    "                                    uncertainty=StdDevUncertainty(hdul['HA6562_FLUX_ERR'].data),\n",
    "                                    mask=np.isnan(hdul['HA6562_FLUX'].data),\n",
    "                                    meta=hdul['HA6562_FLUX'].header,\n",
    "                                    wcs=WCS(hdul['HA6562_FLUX'].header))\n",
    "    \n",
    "                # nebulae mask\n",
    "                filename = data_ext / 'MUSE_DR2.1' / 'Nebulae catalogue' /'spatial_masks'/f'{gal_name}_nebulae_mask.fits'\n",
    "                with fits.open(filename) as hdul:\n",
    "                    nebulae_mask = NDData(hdul[0].data.astype(float),meta=hdul[0].header,wcs=WCS(hdul[0].header))\n",
    "                    nebulae_mask.data[nebulae_mask.data==-1] = np.nan\n",
    "                \n",
    "                # association mask\n",
    "                associations_mask = read_associations(folder=data_ext/'HST',\n",
    "                                                      target=gal_name.lower(),\n",
    "                                                      scalepc=scalepc,\n",
    "                                                      data='mask')\n",
    "            \n",
    "                with fits.open(data_ext/'ALMAv4p0'/f'{gal_name.lower()}_12m+7m+tp_co21_broad_tpeak.fits') as hdul:\n",
    "                    CO = NDData(data=hdul[0].data,\n",
    "                                meta=hdul[0].header,\n",
    "                                wcs=WCS(hdul[0].header))\n",
    "            \n",
    "            ax = next(axes_iter)\n",
    "            \n",
    "            position = row['SkyCoord_neb']\n",
    "            \n",
    "            label = f\"{row['gal_name']}: {row['region_ID']:.0f}/{row['assoc_ID']:.0f}\"\n",
    "\n",
    "            cutout_F275 = Cutout2D(F275.data,position,size=size,wcs=F275.wcs)\n",
    "            norm = simple_norm(cutout_F275.data,stretch='linear',clip=False,percent=99.9)\n",
    "\n",
    "            cutout_CO, _  = reproject_interp(CO,output_projection=cutout_F275.wcs,shape_out=cutout_F275.shape)    \n",
    "            cutout_Halpha, _  = reproject_interp(Halpha,output_projection=cutout_F275.wcs,shape_out=cutout_F275.shape)    \n",
    "\n",
    "            rgb = create_RGB(cutout_CO,cutout_Halpha,cutout_F275.data,\n",
    "                             percentile=[98,98,99.8],weights=[0.7,0.6,1])\n",
    "            #ax.imshow(cutout_image.data,origin='lower',norm=norm,cmap=plt.cm.gray_r)\n",
    "            ax.imshow(rgb,origin='lower')\n",
    "\n",
    "            # plot the nebulae catalogue\n",
    "            cutout_mask, _  = reproject_interp(nebulae_mask,output_projection=cutout_F275.wcs,shape_out=cutout_F275.shape,order='nearest-neighbor')    \n",
    "            region_ID = np.unique(cutout_mask[~np.isnan(cutout_mask)])\n",
    "\n",
    "            contours = []\n",
    "            for i in region_ID:\n",
    "                blank_mask = np.zeros_like(cutout_mask)\n",
    "                blank_mask[cutout_mask==i] = 1\n",
    "                contours += find_contours(blank_mask, 0.5)\n",
    "            for coords in contours:\n",
    "                ax.plot(coords[:,1],coords[:,0],color='tab:green',lw=0.8,label='HII-region')\n",
    "\n",
    "            # 32 pc\n",
    "            cutout_32 = Cutout2D(associations_mask.data,position,size=size,wcs=associations_mask.wcs)\n",
    "            region_ID = np.unique(cutout_32.data[~np.isnan(cutout_32.data)])\n",
    "            contours = []\n",
    "            for i in region_ID:\n",
    "                blank_mask = np.zeros_like(cutout_32.data)\n",
    "                blank_mask[cutout_32.data==i] = 1\n",
    "                contours += find_contours(blank_mask, 0.5)\n",
    "            for coords in contours:\n",
    "                ax.plot(coords[:,1],coords[:,0],color='blue',lw=0.8,label='32pc assoc.')\n",
    "            t = ax.text(0.06,0.87,label, transform=ax.transAxes,color='black',fontsize=8)\n",
    "            t.set_bbox(dict(facecolor='white', alpha=1, ec='white'))\n",
    "            ax.set_xticks([])\n",
    "            ax.set_yticks([])\n",
    "            \n",
    "        plt.subplots_adjust(wspace=-0.01, hspace=0.05)\n",
    "\n",
    "        # only the last page has subplots that need to be removed\n",
    "        h,l = fig.axes[0].get_legend_handles_labels()\n",
    "        ax = next(axes_iter)\n",
    "        ax.axis('off')\n",
    "        ax.legend(h[::len(h)-1],l[::(len(l)-1)],fontsize=7,loc='center',frameon=False)\n",
    "        t = ax.text(0.07,0.87,'name: region ID/assoc ID', transform=ax.transAxes,color='black',fontsize=8)\n",
    "\n",
    "        if j == int(np.ceil(N/Npage))-1:\n",
    "\n",
    "            for i in range(nrows*ncols-len(sub_sample)-1):\n",
    "                # remove the empty axes at the bottom\n",
    "                ax = next(axes_iter)\n",
    "                ax.axis('off')    \n",
    "\n",
    "        pdf.savefig()  # saves the current figure into a pdf page\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### FUV vs ionization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from scipy.stats import binned_statistic, pearsonr, spearmanr\n",
    "\n",
    "sample = set(astrosat_sample) & set(muse_sample)\n",
    "filename = basedir/'reports'/'all_objects_HaFUV_over_SII'\n",
    "\n",
    "#----------------------------------------------\n",
    "# DO NOT MODIFY BELOW\n",
    "#----------------------------------------------\n",
    "ncols = 4\n",
    "nrows = int(np.ceil(len(sample)/ncols))\n",
    "\n",
    "if nrows*ncols<len(sample):\n",
    "    raise ValueError('not enough subplots for selected objects') \n",
    "width = 1.5*two_column\n",
    "fig, axes = plt.subplots(nrows=nrows,ncols=ncols,figsize=(width,width/ncols*nrows))\n",
    "axes_iter = iter(axes.flatten())\n",
    "    \n",
    "#vmin,vmax = np.min(catalogue['HA6562_FLUX_CORR']),np.max(catalogue['HA6562_FLUX_CORR'])\n",
    "vmin,vmax = 1e-16,1e-14\n",
    "# loop over the galaxies we want to plot\n",
    "for name in sorted(sample):  \n",
    "    \n",
    "    tmp = nebulae[(nebulae['gal_name']==name)]\n",
    "        \n",
    "    # get the next axis and find position on the grid\n",
    "    ax = next(axes_iter)\n",
    "    if nrows>1 and ncols>1:\n",
    "        i, j = np.where(axes == ax)\n",
    "        i,j=i[0],j[0]\n",
    "    elif ncols>1:\n",
    "        i,j = 0, np.where(axes==ax)[0]\n",
    "    elif nrows>1:\n",
    "        i,j = np.where(axes==ax)[0],0\n",
    "    else:\n",
    "        i,j=0,0\n",
    "\n",
    "    #catalogue = catalogue[catalogue['HA6562_FLUX']>np.nanpercentile(catalogue['HA6562_FLUX'],50)]\n",
    "    tmp = tmp[tmp['FUV_FLUX_CORR']>3*tmp['FUV_FLUX_CORR_ERR']]\n",
    "    tmp = tmp[tmp['SII6716_FLUX_CORR']>3*tmp['SII6716_FLUX_CORR_ERR']]\n",
    "    tmp = tmp[tmp['SIII9068_FLUX_CORR']>3*tmp['SIII9068_FLUX_CORR_ERR']]\n",
    "\n",
    "    r,p = spearmanr(tmp['[SIII]/[SII]'],tmp['HA/FUV'])\n",
    "    print(f'{name}: rho={r:.2f}, {len(tmp)} objects')\n",
    "\n",
    "    sc = ax.scatter(tmp['[SIII]/[SII]'],tmp['HA/FUV'],\n",
    "               c=1e-20*tmp['HA6562_FLUX_CORR'],vmin=vmin,vmax=vmax,\n",
    "               cmap=plt.cm.plasma,\n",
    "               norm=mpl.colors.LogNorm(),\n",
    "               s=1,marker='.')\n",
    "    \n",
    "    ax.text(0.05,0.9,f'{name}', transform=ax.transAxes,fontsize=7)\n",
    "    ax.text(0.75,0.15,r'$\\rho$'+f'={r:.2f}',transform=ax.transAxes,fontsize=7)\n",
    "    ax.text(0.62,0.05,f'{len(tmp):.0f} objects', transform=ax.transAxes,fontsize=7)\n",
    "    \n",
    "    ax.set(xscale='log',yscale='log',xlim=[1e-2,1],ylim=[2,4e2])\n",
    "    # https://stackoverflow.com/questions/21920233/matplotlib-log-scale-tick-label-number-formatting/33213196\n",
    "    ax.xaxis.set_major_formatter(mpl.ticker.FuncFormatter(lambda y, _: '{:g}'.format(y)))\n",
    "    ax.yaxis.set_major_formatter(mpl.ticker.FuncFormatter(lambda y, _: '{:g}'.format(y)))\n",
    "\n",
    "    if i==nrows-1:\n",
    "        ax.set_xlabel(r'$[\\mathrm{S}\\,\\textsc{iii}]/[\\mathrm{S}\\,\\textsc{ii}]$')\n",
    "    if j==0:\n",
    "        ax.set_ylabel(r'H$\\alpha$ / FUV')\n",
    "\n",
    "        \n",
    "for i in range(nrows*ncols-len(sample)):\n",
    "\n",
    "    # remove the empty axes at the bottom\n",
    "    ax = next(axes_iter)\n",
    "    \n",
    "    if i==0:\n",
    "        #ax.remove()\n",
    "        ax.axis('off')\n",
    "        cbar = fig.colorbar(sc, ax=ax,\n",
    "                            label=r'$\\mathrm{H}\\alpha$ / (erg s$^{-1}$ cm$^{-2}$ Hz$^{-1}$)',\n",
    "                            orientation='horizontal',\n",
    "                           )\n",
    "    else:\n",
    "        ax.remove()\n",
    "\n",
    "    # add the xlabel to the axes above\n",
    "    axes[nrows-2,ncols-1-i].set_xlabel(r'$[\\mathrm{S}\\,\\textsc{iii}]/[\\mathrm{S}\\,\\textsc{ii}]$')\n",
    "\n",
    "\n",
    "#plt.savefig(filename.with_suffix('.png'),dpi=600)\n",
    "#plt.savefig(filename.with_suffix('.pdf'),dpi=600)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Age and Ha/FUV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cluster.auxiliary import bin_stat\n",
    "\n",
    "criteria = (catalogue['mass']>1e3) \n",
    "criteria &= ~np.isnan(catalogue['HA/FUV'])\n",
    "#criteria &= (catalogue['overlap'] == 'contained')\n",
    "#criteria &= (catalogue['neighbors'] == 0)\n",
    "tmp = catalogue[criteria]\n",
    "print(f'sample contains {len(tmp)} objects')\n",
    "\n",
    "\n",
    "xlim = [0.5,10.5]\n",
    "fig,ax=plt.subplots(figsize=(6,4))\n",
    "sc = ax.scatter(tmp['age'],tmp['HA/FUV'],s=10,alpha=0.8,c=tmp['dig/hii'],vmin=0,vmax=1)\n",
    "\n",
    "x,mean,std = bin_stat(tmp['age'],tmp['HA/FUV'],xlim)\n",
    "ax.errorbar(x,mean,yerr=std,fmt='-',color='black',label='mass / Msun')\n",
    "ax.set(xlabel='Age/Myr',ylabel=r'H$\\alpha$ / FUV',xlim=xlim,ylim=[0,100])\n",
    "\n",
    "fig.colorbar(sc,label=r'$f_\\mathrm{dig}/f_\\mathrm{H\\,\\textsc{ii}}$')\n",
    "#ax.set_title(r'only clusters with $M>10^{5}M_\\odot$')\n",
    "\n",
    "plt.savefig(basedir/'reports'/f'all_galaxies_HaFUV_over_age.pdf',dpi=600)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig,(ax1,ax2)=plt.subplots(ncols=2,figsize=(8,3))\n",
    "\n",
    "tmp = catalogue[(catalogue['mass']>1e3) & (catalogue['overlap']=='contained')]\n",
    "ax1.scatter(tmp['dig/hii'],tmp['HA/FUV'],c=tmp['age'],vmin=0,vmax=20,s=2)\n",
    "\n",
    "tmp = catalogue[(catalogue['mass']>1e3) & (catalogue['overlap']=='partial')]\n",
    "sc=ax2.scatter(tmp['dig/hii'],tmp['HA/FUV'],c=tmp['age'],vmin=0,vmax=20,s=2)\n",
    "\n",
    "ax1.set(xlim=[0,1],ylim=[0,100],xlabel=r'$f_\\mathrm{dig}/f_\\mathrm{H\\,\\textsc{ii}}$',ylabel=r'H$\\alpha$/FUV')\n",
    "ax2.set(xlim=[0,1],ylim=[0,100],xlabel=r'$f_\\mathrm{dig}/f_\\mathrm{H\\,\\textsc{ii}}$',ylabel=r'H$\\alpha$/FUV')\n",
    "\n",
    "fig.subplots_adjust(right=0.9)\n",
    "cbar_ax = fig.add_axes([0.93, 0.11, 0.02, 0.84])\n",
    "fig.colorbar(sc,cax=cbar_ax,label='age / Myr')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "seperate subplot for each galaxy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from astropy.coordinates import match_coordinates_sky, search_around_sky\n",
    "from scipy.stats import binned_statistic, pearsonr, spearmanr\n",
    "\n",
    "# '[SIII]/[SII]' , 'HA/FUV', 'AGE_MINCHISQ', 'AGE_BAYES'\n",
    "x_name, y_name = 'age', 'HA/FUV'\n",
    "xlim = [0.5,10.5]\n",
    "bins = 10\n",
    "max_sep = 1*u.arcsec\n",
    "\n",
    "#sample = set(np.unique(nebulae['gal_name'])) & hst_sample\n",
    "sample = np.unique(catalogue['gal_name'])[:-1]\n",
    "\n",
    "filename = basedir/'reports'/'all_objects_age_over_SII.pdf'\n",
    "\n",
    "#----------------------------------------------\n",
    "# DO NOT MODIFY BELOW\n",
    "#----------------------------------------------\n",
    "ncols = 3\n",
    "nrows = int(np.ceil(len(sample)/ncols))\n",
    "\n",
    "if nrows*ncols<len(sample):\n",
    "    raise ValueError('not enough subplots for selected objects') \n",
    "width = two_column\n",
    "fig, axes = plt.subplots(nrows=nrows,ncols=ncols,figsize=(width,width/ncols*nrows))\n",
    "axes_iter = iter(axes.flatten())\n",
    "\n",
    "# loop over the galaxies we want to plot\n",
    "for name in sorted(sample): \n",
    "\n",
    "    # get the next axis and find position on the grid\n",
    "    ax = next(axes_iter)\n",
    "    if nrows>1 and ncols>1:\n",
    "        i, j = np.where(axes == ax)\n",
    "        i,j=i[0],j[0]\n",
    "    elif ncols>1:\n",
    "        i,j = 0, np.where(axes==ax)[0]\n",
    "    elif nrows>1:\n",
    "        i,j = np.where(axes==ax)[0],0\n",
    "    else:\n",
    "        i,j=0,0\n",
    "\n",
    "    criteria = (catalogue['gal_name']==name) \n",
    "    criteria &= (catalogue['mass']>1e3) \n",
    "    #criteria &= ~np.isnan(catalogue['HA/FUV'])\n",
    "    criteria &= (catalogue['overlap'] == 'contained')\n",
    "    #criteria &= (catalogue['neighbors'] == 0)\n",
    "    \n",
    "    tmp = catalogue[criteria]\n",
    "    print(f'{name}: {len(tmp)} objects')\n",
    "    \n",
    "    mean, bin_edges, binnumber = binned_statistic(tmp[x_name],\n",
    "                                                  tmp[y_name],\n",
    "                                                  statistic='mean',\n",
    "                                                  bins=bins,\n",
    "                                                  range=xlim)\n",
    "    std, _, _ = binned_statistic(tmp[x_name],\n",
    "                                  tmp[y_name],\n",
    "                                  statistic='std',\n",
    "                                  bins=bins,\n",
    "                                  range=xlim)\n",
    "\n",
    "    ax.scatter(tmp[x_name],tmp[y_name],color='tab:blue',s=1)\n",
    "    # plot the standard divation with yerr=std\n",
    "    ax.errorbar((bin_edges[1:]+bin_edges[:-1])/2,mean,fmt='-')\n",
    "    ax.text(0.65,0.85,f'{name}', transform=ax.transAxes,fontsize=7)\n",
    "\n",
    "    ax.set(xlim=xlim)\n",
    "    if i==nrows-1:\n",
    "        ax.set_xlabel(f'{x_name.replace(\"_\",\" \")}')\n",
    "    if j==0:\n",
    "        ax.set_ylabel(f'{y_name.replace(\"_\",\" \")}')\n",
    "\n",
    "for i in range(nrows*ncols-len(sample)):\n",
    "\n",
    "    # remove the empty axes at the bottom\n",
    "    ax = next(axes_iter)\n",
    "    ax.remove()\n",
    "\n",
    "    # add the xlabel to the axes above\n",
    "    axes[nrows-2,ncols-1-i].set_xlabel(f'{x_name.replace(\"_\",\" \")}')\n",
    "\n",
    "\n",
    "plt.savefig(filename,dpi=600)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from astropy.coordinates import match_coordinates_sky, search_around_sky\n",
    "\n",
    "# '[SIII]/[SII]' , 'HA/FUV'\n",
    "x_name, y_name, z_name = '[SIII]/[SII]', 'HA/FUV', 'AGE_MINCHISQ'\n",
    "xlim = [0.5,10.5]\n",
    "bins = 10\n",
    "max_sep = 2*u.arcsec\n",
    "\n",
    "sample = muse_sample & hst_sample & astrosat_sample\n",
    "\n",
    "filename = basedir/'reports'/'all_objects_FUV_over_SII_with_age.pdf'\n",
    "\n",
    "#----------------------------------------------\n",
    "# DO NOT MODIFY BELOW\n",
    "#----------------------------------------------\n",
    "ncols = 2\n",
    "nrows = int(np.ceil(len(sample)/ncols))\n",
    "\n",
    "if nrows*ncols<len(sample):\n",
    "    raise ValueError('not enough subplots for selected objects') \n",
    "width = two_column\n",
    "fig, axes = plt.subplots(nrows=nrows,ncols=ncols,figsize=(width,width/ncols*nrows))\n",
    "axes_iter = iter(axes.flatten())\n",
    "\n",
    "# loop over the galaxies we want to plot\n",
    "for name in sorted(sample): \n",
    "\n",
    "    # it makes a different if we match the clusters to the nebulae or the other way around\n",
    "    catalogcoord = clusters[clusters['gal_name']==name].copy()\n",
    "    matchcoord   = nebulae[nebulae['gal_name']==name].copy()\n",
    "\n",
    "    idx, sep, _ = match_coordinates_sky(matchcoord['SkyCoord'],catalogcoord['SkyCoord'])\n",
    "\n",
    "    catalogue = matchcoord.copy()\n",
    "\n",
    "    for col in catalogcoord.columns:\n",
    "        if col in catalogue.columns:\n",
    "            catalogue[f'{col}2'] = catalogcoord[idx][col]\n",
    "        else:\n",
    "            catalogue[col] = catalogcoord[idx][col]\n",
    "\n",
    "    catalogue['sep'] = sep\n",
    "    catalogue = catalogue[sep.__lt__(max_sep)]\n",
    "    catalogue = catalogue[~np.isnan(catalogue[x_name]) & ~np.isnan(catalogue[y_name]) & (catalogue['AGE_MINCHISQ']<10)]\n",
    "    print(f'{name}: {len(catalogue)} objects in joined catalogue')\n",
    "\n",
    "    # get the next axis and find position on the grid\n",
    "    ax = next(axes_iter)\n",
    "    if nrows>1 and ncols>1:\n",
    "        i, j = np.where(axes == ax)\n",
    "        i,j=i[0],j[0]\n",
    "    elif ncols>1:\n",
    "        i,j = 0, np.where(axes==ax)[0]\n",
    "    elif nrows>1:\n",
    "        i,j = np.where(axes==ax)[0],0\n",
    "    else:\n",
    "        i,j=0,0\n",
    "\n",
    "    #catalogue = catalogue[catalogue['HA6562_FLUX']>np.nanpercentile(catalogue['HA6562_FLUX'],50)]\n",
    "    #catalogue = catalogue[catalogue['FUV_FLUX_CORR']>3*catalogue['FUV_FLUX_CORR_ERR']]\n",
    "    #catalogue = catalogue[catalogue['SII6716_FLUX_CORR']>3*catalogue['SII6716_FLUX_CORR_ERR']]\n",
    "    #catalogue = catalogue[catalogue['SIII9068_FLUX_CORR']>3*catalogue['SIII9068_FLUX_CORR_ERR']]\n",
    "\n",
    "    r,p = spearmanr(catalogue['[SIII]/[SII]'],catalogue['HA/FUV'])\n",
    "    print(f'{name}: rho={r:.2f}, {len(catalogue)} objects')\n",
    "\n",
    "    sc = ax.scatter(catalogue['[SIII]/[SII]'],catalogue['HA/FUV'],\n",
    "                    c=catalogue[z_name],vmin=0, vmax=10,cmap=plt.cm.RdBu_r,\n",
    "                    s=3,marker='.')\n",
    "    \n",
    "    ax.text(0.05,0.9,f'{name}', transform=ax.transAxes,fontsize=7)\n",
    "    ax.text(0.7,0.15,r'$\\rho$'+f'={r:.2f}',transform=ax.transAxes,fontsize=7)\n",
    "    ax.text(0.55,0.05,f'{len(catalogue):.0f} objects', transform=ax.transAxes,fontsize=7)\n",
    "    \n",
    "    ax.set(xscale='log',yscale='log',xlim=[1e-2,1],ylim=[2,2e2])\n",
    "    # https://stackoverflow.com/questions/21920233/matplotlib-log-scale-tick-label-number-formatting/33213196\n",
    "    ax.xaxis.set_major_formatter(mpl.ticker.FuncFormatter(lambda y, _: '{:g}'.format(y)))\n",
    "    ax.yaxis.set_major_formatter(mpl.ticker.FuncFormatter(lambda y, _: '{:g}'.format(y)))\n",
    "\n",
    "    if i==nrows-1:\n",
    "        ax.set_xlabel('[SIII]/[SII]')\n",
    "    if j==0:\n",
    "        ax.set_ylabel(r'H$\\alpha$ / FUV')\n",
    "\n",
    "fig.colorbar(sc,ax=axes.ravel().tolist(),label=f'{z_name.replace(\"_\",\" \")}')\n",
    "        \n",
    "for i in range(nrows*ncols-len(sample)):\n",
    "\n",
    "    # remove the empty axes at the bottom\n",
    "    ax = next(axes_iter)\n",
    "    ax.remove()\n",
    "\n",
    "    # add the xlabel to the axes above\n",
    "    axes[nrows-2,ncols-1-i].set_xlabel(f'{x_name.replace(\"_\",\" \")}')\n",
    "\n",
    "\n",
    "plt.savefig(filename,dpi=600)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### age histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fig,(ax1,ax2,ax3)=plt.subplots(ncols=3,figsize=(10,3))\n",
    "bins = np.arange(0,10,1)\n",
    "\n",
    "tmp = associations[(associations['mass']>1e3) & (associations['age']<10)]\n",
    "\n",
    "ages_con = tmp[tmp['overlap']=='contained']['age']\n",
    "ages_par = tmp[tmp['overlap']=='partial']['age']\n",
    "ages_iso = tmp[tmp['overlap']=='isolated']['age']\n",
    "\n",
    "print(f'ages: con={np.mean(ages_con):.2f}, par={np.mean(ages_par):.2f}, iso={np.mean(ages_iso):.2f}')\n",
    "\n",
    "ax1.hist(ages_con,bins=bins,histtype='step',label='contained')\n",
    "ax2.hist(ages_par,bins=bins,histtype='step',label='partially')\n",
    "ax3.hist(ages_iso,bins=bins,histtype='step',label='isolated')\n",
    "\n",
    "ax1.set_title(f'contained ({np.nanmean(ages_con):.2f} Myr)')\n",
    "ax2.set_title(f'partially ({np.nanmean(ages_par):.2f} Myr)')\n",
    "ax3.set_title(f'isolated ({np.nanmean(ages_iso):.2f} Myr)')\n",
    "\n",
    "for ax in [ax1,ax2,ax3]:\n",
    "    ax.set(ylim=[0,600],xlabel='age / Myr')\n",
    "plt.savefig(basedir/'reports'/f'all_galaxies_age_hist_contained.pdf',dpi=600)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from astropy.coordinates import match_coordinates_sky\n",
    "\n",
    "tmp = associations[(associations['mass']>1e3) & (associations['age']<10)]\n",
    "idx,sep,_=match_coordinates_sky(tmp['SkyCoord'],nebulae['SkyCoord'])\n",
    "\n",
    "ages1 = tmp[(sep<0.4*u.arcsec)]['age']\n",
    "ages2 = tmp[(sep>0.4*u.arcsec) & (sep<0.8*u.arcsec)]['age']\n",
    "ages3 = tmp[(sep>0.8*u.arcsec)]['age']\n",
    "\n",
    "print(f'mean age: 1={np.mean(ages1):.2f}, 2={np.mean(ages2):.2f}, 3={np.mean(ages3):.2f} Myr')\n",
    "\n",
    "fig,(ax1,ax2,ax3)=plt.subplots(ncols=3,figsize=(10,3))\n",
    "bins = np.arange(0,10,1)\n",
    "\n",
    "ax1.hist(ages1,bins=bins,histtype='step',label='isolated')\n",
    "ax2.hist(ages2,bins=bins,histtype='step',label='partially')\n",
    "ax3.hist(ages3,bins=bins,histtype='step',label='contained')\n",
    "ax1.set_title(r'$s<0.4\"$'+f' ({np.mean(ages1):.2f} Myr)')\n",
    "ax2.set_title(r'$0.4\"<s<0.8\"$' +f' ({np.mean(ages2):.2f} Myr)')\n",
    "ax3.set_title(r'$0.8\"<s$'+f' ({np.mean(ages3):.2f} Myr)')\n",
    "\n",
    "for ax in [ax1,ax2,ax3]:\n",
    "    ax.set(ylim=[0,600],xlabel='age / Myr')\n",
    "plt.savefig(basedir/'reports'/f'all_galaxies_age_hist_sep.pdf',dpi=600)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "tmp = catalogue[(catalogue['mass']>1e3) & (catalogue['age']<10)]\n",
    "\n",
    "p1,p2=np.nanpercentile(tmp['HA/FUV'],[33,66])\n",
    "\n",
    "ages1 = tmp[tmp['HA/FUV']>p2]['age']\n",
    "ages2 = tmp[(tmp['HA/FUV']>p1) & (tmp['HA/FUV']<p2)]['age']\n",
    "ages3 = tmp[(tmp['HA/FUV']<p1)]['age']\n",
    "\n",
    "print(f'mean age: 1={np.mean(ages1):.2f}, 2={np.mean(ages2):.2f}, 3={np.mean(ages3):.2f} Myr')\n",
    "\n",
    "fig,(ax1,ax2,ax3)=plt.subplots(ncols=3,figsize=(10,3))\n",
    "bins = np.arange(0,10,1)\n",
    "\n",
    "ax1.hist(ages1,bins=bins,histtype='step',label='isolated')\n",
    "ax2.hist(ages2,bins=bins,histtype='step',label='partially')\n",
    "ax3.hist(ages3,bins=bins,histtype='step',label='contained')\n",
    "ax1.set_title(r'first percentile in Ha/FUV'+f' ({np.mean(ages1):.2f} Myr)')\n",
    "ax2.set_title(r'second percentile in Ha/FUV' +f' ({np.mean(ages2):.2f} Myr)')\n",
    "ax3.set_title(r'third percentile in Ha/FUV'+f' ({np.mean(ages3):.2f} Myr)')\n",
    "\n",
    "for ax in [ax1,ax2,ax3]:\n",
    "    ax.set(ylim=[0,200],xlabel='age / Myr')\n",
    "plt.savefig(basedir/'reports'/f'all_galaxies_age_hist_HaFUV.pdf',dpi=600)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EBV\n",
    "\n",
    "we expect \n",
    "$$\n",
    "E(B-V)_{balmer} = 2 \\cdot E(B-V)_{stars}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "criteria = (catalogue['mass']>1e3) #& (catalogue['overlap']=='contained') & (catalogue['age']<10)\n",
    "tmp = catalogue[criteria]\n",
    "print(f'sample contains {len(tmp)} objects')\n",
    "\n",
    "cmap = plt.cm.get_cmap('viridis',5)\n",
    "fig = plt.figure(figsize=(single_column,single_column/1.1))\n",
    "ax = fig.add_subplot()\n",
    "divider = make_axes_locatable(ax)\n",
    "cax = divider.append_axes('right', size=\"10%\", pad=0.2,)\n",
    "\n",
    "xlim = [0,10]\n",
    "sc=ax.scatter(tmp['EBV_stars'],tmp['EBV_balmer'],c=tmp['age'],s=3,vmin=0,vmax=10,cmap=cmap)\n",
    "ax.plot([0,1],[0,2],color='black')\n",
    "ax.plot([0,2],[0,2],color='black')\n",
    "fig.colorbar(sc,label='age / Myr',cax=cax)\n",
    "ax.set(xlim=[0,0.7],ylim=[0,0.7],xlabel='E(B-V) stars',ylabel='E(B-V) Balmer')\n",
    "\n",
    "#plt.savefig(basedir/'reports'/f'all_galaxies_{scalepc}_EBV_Balmer_vs_Stars.pdf',dpi=600)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import spearmanr\n",
    "\n",
    "age_bins = np.array([0,2,4,6,8,10])\n",
    "\n",
    "for low,high in zip(age_bins[:-1],age_bins[1:]):\n",
    "    t = tmp[(tmp['age']>low) & (tmp['age']<high)]\n",
    "    r,p = spearmanr(t['EBV_stars'],t['EBV_balmer'])\n",
    "    print(f'{low} to {high} Myr: rho={r:.2f}, {len(t)} objects')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Corner Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from cluster.plot import corner\n",
    "\n",
    "tmp = catalogue[(catalogue['overlap']=='contained') & (catalogue['mass']>1e3) & catalogue['uniform_age']]\n",
    "print(f'sample contains {len(tmp)} objects')\n",
    "\n",
    "filename = basedir/'reports'/f'all_galaxies_corner.pdf'\n",
    "columns  = ['age','HA/FUV','eq_width','met_scal','logq_D91','EBV_stars','EBV_balmer','dig_median']\n",
    "limits   = {'age':(0,10),'eq_width':(0,100),'HA/FUV':(0,50),'HA/NUV':(0,20),'met_scal':(8.4,8.7),'logq_D91':(6,8)}\n",
    "\n",
    "corner(tmp,columns,limits,nbins=5,filename=filename,vmin=1000,vmax=1e6,figsize=(18,18))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "with open(basedir/'data'/'map_nebulae_association'/f'{name}_{scalepc}pc_nebulae.yml') as f:\n",
    "    nebulae_dict = yaml.load(f,Loader=yaml.SafeLoader)\n",
    "with open(basedir/'data'/'map_nebulae_association'/f'{name}_{scalepc}pc_associations.yml') as f:\n",
    "    associations_dict = yaml.load(f,Loader=yaml.SafeLoader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare all with Starburst99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from starburst import Cluster, find_model, make_folder, list_available_models\n",
    "\n",
    "cluster = Cluster(stellar_model='GENEVAv40',metallicity=0.014)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for each association, calculate the predicted number of ionizing photons based on the mass and the age of the association.\n",
    "\n",
    "The observed number of ionizing photos is calulcated based on the conversion factor from Niederhofer+2016 (or Kennicutt+98)\n",
    "\n",
    "$$\n",
    "Q(\\mathrm{H}^0) = 7.31\\cdot 10^{11} L(\\mathrm{H}\\alpha)\n",
    "$$\n",
    "\n",
    "we only use a subsample (high mass, contained, speparated etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "catalogue['Qpredicted'] = np.nan\n",
    "HI_rate = cluster.quanta['HI_rate'].value\n",
    "time = cluster.quanta['Time']\n",
    "for row in tqdm(catalogue):\n",
    "    idx = np.argmin(np.abs(time-row['age']*u.Myr))\n",
    "    row['Qpredicted'] = HI_rate[idx] * row['mass'] / cluster.mass\n",
    "    \n",
    "catalogue['distance'] = np.nan\n",
    "for gal_name in catalogue['gal_name']:\n",
    "    distance = Distance(distmod=sample_table.loc[gal_name]['(m-M)'])\n",
    "    catalogue['distance'][catalogue['gal_name']==gal_name] = distance\n",
    "    \n",
    "catalogue['L(Ha)'] = (catalogue['HA6562_FLUX_CORR']*1e-20*u.erg/u.s/u.cm**2 *4*np.pi*(catalogue['distance']*u.Mpc)**2).to(u.erg/u.s)\n",
    "catalogue['Qobserved'] = 7.31e11*catalogue['L(Ha)']/u.erg\n",
    "fesc = (catalogue['Qpredicted']-catalogue['Qobserved'])/catalogue['Qpredicted']\n",
    "catalogue['fesc'] = fesc\n",
    "\n",
    "print(f'fesc={np.nanmean(fesc[fesc>0]):.2f} (from {np.sum(fesc>0)} objects)')\n",
    "print(f\"{np.sum(fesc<0)} of {len(catalogue)} ({np.sum(fesc<0)/len(catalogue)*100:.1f}%) regions have negative fesc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for objects with negative fesc we redo the analysis with age-age_err\n",
    "Qpredict_new = []\n",
    "for row in tqdm(catalogue):\n",
    "    if row['fesc']<0:\n",
    "        idx = np.argmin(np.abs(time-(row['age']-row['age_err'])*u.Myr))\n",
    "        row['Qpredicted'] = ( HI_rate[idx] * row['mass'] / cluster.mass )\n",
    "\n",
    "fesc = (catalogue['Qpredicted']-catalogue['Qobserved'])/catalogue['Qpredicted']\n",
    "catalogue['fesc'] = fesc\n",
    "\n",
    "print(f'fesc={np.nanmean(fesc[fesc>0]):.2f} (from {np.sum(fesc>0)} objects)')\n",
    "print(f\"{np.sum(fesc<0)} of {len(catalogue)} ({np.sum(fesc<0)/len(catalogue)*100:.1f}%) regions have negative fesc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criteria  = (catalogue['mass']>1e3) \n",
    "#criteria &= (catalogue['age']<=20) \n",
    "#criteria &= (catalogue['uniform_age']) \n",
    "criteria &= (catalogue['overlap']=='contained') \n",
    "#criteria &= fesc>0\n",
    "tmp = catalogue[criteria].copy()\n",
    "\n",
    "print(f'fesc={np.nanmean(tmp[tmp[\"fesc\"]>0][\"fesc\"]):.2f} (from {np.sum(criteria)} objects)')\n",
    "print(f\"{np.sum(tmp['fesc']<0)} of {len(tmp)} ({np.sum(tmp['fesc']<0)/len(tmp)*100:.1f}%) regions have negative fesc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot escape fraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax =plt.subplots(figsize=(single_column,0.9*single_column))\n",
    "\n",
    "print(f'fesc={np.mean(fesc[fesc>0]):.2f}')\n",
    "\n",
    "Qpredicted = np.logspace(48,52)\n",
    "cmap = plt.cm.get_cmap('copper',6)\n",
    "lines = [\"-\",\"--\",\"-.\",\":\"]\n",
    "for i,f in enumerate([0.0,0.5,0.9,0.99]):\n",
    "    Qobserved = Qpredicted*(1-f)\n",
    "    ax.plot(np.log10(Qpredicted),np.log10(Qobserved),ls=lines[i],c='k',label=f'$f_\\mathrm{{esc}}={f}$',zorder=1)\n",
    "\n",
    "sc=ax.scatter(np.log10(tmp['Qpredicted']),np.log10(tmp['Qobserved']),\n",
    "              c=tmp['dig/hii'],cmap=cmap,vmin=0.,vmax=1.,s=2,zorder=2)\n",
    "ax.legend()\n",
    "fig.colorbar(sc,label=r'$f_\\mathrm{dig}/f_\\mathrm{H\\,\\textsc{ii}}$')\n",
    "#fig.colorbar(sc,label='$\\log_{10} q$ (from Diaz+91)')\n",
    "\n",
    "ax.set(xlabel=r'$\\log_{10} (\\mathcal{Q (\\mathrm{H}^0)} / \\mathrm{s}^{-1})$ predicted (SB99)',\n",
    "       ylabel=r'$\\log_{10} (\\mathcal{Q (\\mathrm{H}^0)} / \\mathrm{s}^{-1})$ observed (MUSE)',\n",
    "       xlim=[48,52],ylim=[48,52])\n",
    "\n",
    "ax.xaxis.set_major_locator(mpl.ticker.MaxNLocator(4)) \n",
    "ax.yaxis.set_major_locator(mpl.ticker.MaxNLocator(4)) \n",
    "\n",
    "plt.savefig(basedir/'reports'/f'escape_fraction.pdf',dpi=600)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,((ax1,ax2),(ax3,ax4),(ax5,ax6)) =plt.subplots(ncols=2,nrows=3,figsize=(two_column,1.2*two_column))\n",
    "\n",
    "print(f'fesc={np.mean(fesc[fesc>0]):.2f}')\n",
    "\n",
    "Qpredicted = np.logspace(48,52)\n",
    "\n",
    "lines = [\"-\",\"--\",\"-.\",\":\"]\n",
    "for i,f in enumerate([0.0,0.5,0.9,0.99]):\n",
    "    Qobserved = Qpredicted*(1-f)\n",
    "    for ax in (ax1,ax2,ax3,ax4,ax5,ax6):\n",
    "        ax.plot(np.log10(Qpredicted),np.log10(Qobserved),ls=lines[i],c='k',label=f'$f_\\mathrm{{esc}}={f}$',zorder=1)\n",
    "\n",
    "cmap = plt.cm.get_cmap('plasma',6)\n",
    "sc1=ax1.scatter(np.log10(tmp['Qpredicted']),np.log10(tmp['Qobserved']),\n",
    "              c=tmp['logq_D91'],cmap=cmap,vmin=6,vmax=8,s=2,zorder=2)\n",
    "cmap = plt.cm.get_cmap('copper',6)\n",
    "sc2=ax2.scatter(np.log10(tmp['Qpredicted']),np.log10(tmp['Qobserved']),\n",
    "              c=tmp['dig/hii'],cmap=cmap,vmin=0,vmax=1,s=2,zorder=2)\n",
    "cmap = plt.cm.get_cmap('viridis',6)\n",
    "sc3=ax3.scatter(np.log10(tmp['Qpredicted']),np.log10(tmp['Qobserved']),\n",
    "              c=tmp['EBV_stars'],cmap=cmap,vmin=0,vmax=0.8,s=2,zorder=2)\n",
    "cmap = plt.cm.get_cmap('cividis',6)\n",
    "sc4=ax4.scatter(np.log10(tmp['Qpredicted']),np.log10(tmp['Qobserved']),\n",
    "              c=tmp['age'],cmap=cmap,vmin=0,vmax=10,s=2,zorder=2)\n",
    "cmap = plt.cm.get_cmap('ocean',6)\n",
    "sc5=ax5.scatter(np.log10(tmp['Qpredicted']),np.log10(tmp['Qobserved']),\n",
    "              c=np.log10(tmp['mass']),cmap=cmap,vmin=3,vmax=5.3,s=2,zorder=2)\n",
    "cmap = plt.cm.get_cmap('magma',6)\n",
    "sc6=ax6.scatter(np.log10(tmp['Qpredicted']),np.log10(tmp['Qobserved']),\n",
    "              c=tmp['galactic_radius'],cmap=cmap,vmin=0,vmax=2,s=2,zorder=2)\n",
    "\n",
    "\n",
    "ax1.legend()\n",
    "fig.colorbar(sc1,ax=ax1,label=r'$\\log q$ (from Diaz 91)')\n",
    "fig.colorbar(sc2,ax=ax2,label=r'$f_\\mathrm{dig}/f_\\mathrm{H\\,\\textsc{ii}}$')\n",
    "fig.colorbar(sc3,ax=ax3,label=r'$E(B-V)_\\mathrm{stars}$')\n",
    "fig.colorbar(sc4,ax=ax4,label=r'age / Myr')\n",
    "fig.colorbar(sc5,ax=ax5,label=r'$\\log_{10} M/\\mathrm{M}_\\odot$')\n",
    "fig.colorbar(sc6,ax=ax6,label=r'galactic radius / arcmin')\n",
    "\n",
    "for ax in (ax5,ax6):\n",
    "    ax.set(xlabel=r'$\\log_{10} (\\mathcal{Q (\\mathrm{H}^0)} / \\mathrm{s}^{-1})$ predicted')\n",
    "for ax in (ax1,ax3,ax5):\n",
    "    ax.set(ylabel=r'$\\log_{10} (\\mathcal{Q (\\mathrm{H}^0)} / \\mathrm{s}^{-1})$ observed')\n",
    "\n",
    "for ax in (ax1,ax2,ax3,ax4,ax5,ax6):\n",
    "    ax.set(xlim=[48,52],ylim=[48,52])\n",
    "    ax.xaxis.set_major_locator(mpl.ticker.MaxNLocator(4)) \n",
    "    ax.yaxis.set_major_locator(mpl.ticker.MaxNLocator(4)) \n",
    "plt.tight_layout()\n",
    "plt.savefig(basedir/'reports'/f'escape_fraction.pdf',dpi=600)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax =plt.subplots(figsize=(single_column,single_column))\n",
    "\n",
    "ax.scatter(tmp['fesc'],tmp['dig/hii'])\n",
    "ax.set(xlim=[0,1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mass vs observed Halpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate Ha on a grid of different ages/masses with Starburst99\n",
    "age_grid = np.array([2,6,10,14,18])*u.Myr\n",
    "mass_grid = np.logspace(2,7,10)\n",
    "ionizing_photons = np.zeros((len(age_grid),len(mass_grid)))\n",
    "for i,mass in enumerate(mass_grid):\n",
    "    scaled_cluster = cluster.scale(mass)\n",
    "    for j,age in enumerate(age_grid):\n",
    "        idx = np.argmin(np.abs(scaled_cluster.quanta['Time']-age))\n",
    "        ionizing_photons[j,i] = scaled_cluster.quanta['HI_rate'][idx].value\n",
    "distance = 10*u.Mpc\n",
    "LHa = ionizing_photons / 7.31e11 * u.erg \n",
    "FHa = LHa / (1e-20*u.erg/u.s/u.cm**2 *4*np.pi*distance**2).to(u.erg/u.s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nrows, ncols = 2,4\n",
    "\n",
    "cmap = plt.cm.get_cmap('copper', 5)\n",
    "fig=plt.figure(figsize=(two_column,nrows/ncols*two_column))\n",
    "axes = []\n",
    "for i,gal_name in enumerate(np.unique(tmp['gal_name'])):\n",
    "    ax = fig.add_subplot(nrows,ncols,i+1)\n",
    "    axes.append(ax)\n",
    "    sub = tmp[tmp['gal_name']==gal_name]\n",
    "    \n",
    "    distance = sub['distance'][0]*u.Mpc\n",
    "    LHa = ionizing_photons / 7.31e11 * u.erg \n",
    "    FHa = LHa / (u.erg/u.s/u.cm**2 *4*np.pi*distance**2).to(u.erg/u.s)\n",
    "    \n",
    "    sc=ax.scatter(sub['mass'],1e-20*sub['HA6562_FLUX_CORR'],s=3,\n",
    "               c=sub['age'],cmap=cmap,vmin=0,vmax=20,zorder=2)\n",
    "    \n",
    "    # plot the theoretical liens\n",
    "    for j,age in enumerate(age_grid):\n",
    "        color = cmap(age/20/u.Myr)\n",
    "        ax.plot(mass_grid,FHa[j,:],label=age,color=color)\n",
    "    \n",
    "    ax.set(xlim=[1e3,1e6],ylim=[5e-17,5e-12],xscale='log',yscale='log')\n",
    "    ax.text(0.05,0.9,f'{gal_name}', transform=ax.transAxes,fontsize=7)\n",
    "\n",
    "    if i%ncols==0:\n",
    "        ax.set(ylabel=r'$F(\\mathrm{H}\\alpha)$ / erg s$^{-1}$ cm$^{-2}$')\n",
    "    else:\n",
    "        ax.set_yticklabels([])\n",
    "    if i//ncols==nrows-1:\n",
    "        ax.set(xlabel=r'mass / M$_\\odot$')\n",
    "    else:\n",
    "        ax.set_xticklabels([])\n",
    "\n",
    "# Create the legend\n",
    "h,l = axes[0].get_legend_handles_labels()\n",
    "fig.legend(h,l,\n",
    "           ncol=5,\n",
    "           loc=\"upper center\",   # Position of legend\n",
    "           borderaxespad=0.2,    # Small spacing around legend box\n",
    "           )\n",
    "plt.tight_layout()\n",
    "fig.subplots_adjust(right=0.9)\n",
    "cbar_ax = fig.add_axes([0.93, 0.11, 0.02, 0.84])\n",
    "fig.colorbar(sc,cax=cbar_ax,label='age / Myr',ticks=age_grid)\n",
    "\n",
    "plt.savefig(basedir/'reports'/'mass_vs_Halpha.pdf',dpi=600)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BPT_diagram(R3,N2,S2,O1,label='',filename=None,**kwargs):\n",
    "    '''create a BPT diagram\n",
    "    \n",
    "    Parameters \n",
    "    ----------\n",
    "    \n",
    "    R3 : array\n",
    "        log10([OIII]/Hbeta)\n",
    "        \n",
    "    N2 : array\n",
    "        log10([NII]/Halpha)\n",
    "        \n",
    "    S2 : array\n",
    "        log10([SII]/Halpha)\n",
    "        \n",
    "    O1 : array\n",
    "        log10([OI]/Halpha)\n",
    "        \n",
    "    Other Parameters\n",
    "    ----------------\n",
    "    \n",
    "    **kwargs : passed to plt.scatter()\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    fig,(ax1,ax2,ax3) = plt.subplots(ncols=3,figsize=(two_column,two_column/3))\n",
    "        \n",
    "    x = np.linspace(-2.5,2.5,200)\n",
    "    \n",
    "    # ---- N2 vs R3 plot ----\n",
    "    ax1.scatter(N2,R3,**kwargs)\n",
    "    ax1.plot(x[x<0.47],0.61/(x[x<0.47]-0.47)+1.19,color='black',ls='--',label='Kewley+2001')\n",
    "    ax1.plot(x[x<-0.032],0.359/(x[x<-0.032]+0.032)+1.083,color='black',ls='-',label='Law+2021')\n",
    "    #ax1.legend() \n",
    "    \n",
    "    ax1.set(xlim=[-1.5,0.5],ylim=[-1.5,1],\n",
    "            xlabel=r'$\\log ( [\\mathrm{N}\\,\\textsc{ii}] / \\mathrm{H}\\alpha )$',\n",
    "            ylabel=r'$\\log ([\\mathrm{O}\\,\\textsc{iii}] / \\mathrm{H}\\beta )$')\n",
    "    \n",
    "    # ---- S2 vs R3 plot ----    \n",
    "    ax2.scatter(S2,R3,**kwargs)\n",
    "    ax2.plot(x[x<0.32],0.72/(x[x<0.32]-0.32)+1.3,color='black',ls='--',label='Kewley+2001')\n",
    "    ax2.plot(x[x>-0.33],1.89*x[x>-0.33]+0.76,color='black',ls='--',label='Kewley+2001')\n",
    "    ax2.plot(x[x<0.198],0.41/(x[x<0.198]-0.198)+1.164,color='black',ls='-',label='Law+2021')\n",
    "\n",
    "    ax2.set(xlim=[-1.5,0.5],ylim=[-1.5,1],\n",
    "            xlabel=r'$\\log ( [\\mathrm{S}\\,\\textsc{ii}] / \\mathrm{H}\\alpha )$')\n",
    "\n",
    "    # ---- O1 vs R3 plot ----\n",
    "    sc = ax3.scatter(O1,R3,**kwargs)\n",
    "    ax3.plot(x[x<-0.53],0.73/(x[x<-0.53]+0.53)+1.33,color='black',ls='--',label='Kewley+2001')\n",
    "    ax3.plot(x,0.612/(x+0.36)+1.179,color='black',ls='-',label='Law+2021')\n",
    "    \n",
    "    ax3.set(xlim=[-2.5,-0.5],ylim=[-1.5,1],\n",
    "            xlabel=r'$\\log ( [\\mathrm{O}\\,\\textsc{i}] / \\mathrm{H}\\alpha )$')\n",
    "\n",
    "    for ax in (ax1,ax2,ax3):\n",
    "        ax.grid()\n",
    "        \n",
    "    plt.tight_layout()\n",
    "    fig.subplots_adjust(right=0.9)\n",
    "    cbar_ax = fig.add_axes([0.95, 0.2, 0.02, 0.72])\n",
    "    fig.colorbar(sc,cax=cbar_ax,label=label)\n",
    "    \n",
    "    if filename:\n",
    "        plt.savefig(filename,dpi=600)\n",
    "        \n",
    "    plt.show()\n",
    "\n",
    "\n",
    "BPT_diagram(R3=np.log10(tmp['OIII5006_FLUX_CORR']/tmp['HB4861_FLUX_CORR']),\n",
    "            N2=np.log10(tmp['NII6583_FLUX_CORR']/tmp['HA6562_FLUX_CORR']),\n",
    "            S2=np.log10((tmp['SII6716_FLUX_CORR']+tmp['SII6730_FLUX_CORR'])/tmp['HA6562_FLUX_CORR']),\n",
    "            O1=np.log10(tmp['OI6300_FLUX_CORR']/tmp['HA6562_FLUX_CORR']),\n",
    "            c=tmp['fesc'],vmin=0,vmax=1,cmap=plt.cm.get_cmap('copper', 5),s=2,\n",
    "            label=r'$f_\\mathrm{esc}$',filename=basedir/'reports'/'BPT.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = ['#500093','#8B07F3','#B42003','#D65800','#F2BB00']\n",
    "cmap = mpl.colors.LinearSegmentedColormap('FB',[mpl.colors.to_rgb(x) for x in colors])\n",
    "\n",
    "plt.scatter([1,2,3,4],[1,2,3,4],c=[0,5,3,4],cmap=cmap)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots(figsize=(6,4))\n",
    "\n",
    "logbins = np.logspace(3,7,20)\n",
    "sub = associations[associations['overlap']=='isolated']\n",
    "ax.hist(sub['mass'],bins=logbins,label='isolated',alpha=0.6)\n",
    "\n",
    "sub = associations[associations['overlap']=='partial']\n",
    "ax.hist(sub['mass'],bins=logbins,label='partial',alpha=0.6)\n",
    "\n",
    "sub = associations[associations['overlap']=='contained']\n",
    "ax.hist(sub['mass'],bins=logbins,label='contained',alpha=0.6)\n",
    "\n",
    "ax.set(xlabel='mass / Msun',xscale='log')\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Plot regions (MUSE & HST over WFI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from astropy.nddata import Cutout2D\n",
    "from cluster.regions import find_sky_region\n",
    "\n",
    "sample = set([x.stem.split('_')[0].upper() for x in (data_ext/'HST'/'white_light').iterdir()])\n",
    "sample = muse_sample\n",
    "ncols = 5\n",
    "nrows = int(np.ceil(len(sample)/ncols))\n",
    "\n",
    "width = 1.5*two_column\n",
    "fig, axes = plt.subplots(nrows=nrows,ncols=ncols,figsize=(width,width/ncols*nrows))\n",
    "axes_iter = iter(axes.flatten())\n",
    "\n",
    "for name in sorted(sample):\n",
    "    \n",
    "    print(name)\n",
    "    \n",
    "    if name in hst_sample:\n",
    "        with fits.open(data_ext / 'HST' / 'white_light' / f'{name.lower()}_white_24rgb.fits') as hdul:\n",
    "            hst_whitelight = NDData(hdul[0].data,mask=hdul[0].data==0,meta=hdul[0].header,wcs=WCS(hdul[0].header))\n",
    "            hst_whitelight.data[hst_whitelight.data==0] = np.nan\n",
    "        \n",
    "    filename = data_ext / 'MUSE_DR2' / 'MUSEDAP' / f'{name}_MAPS.fits'\n",
    "    with fits.open(filename) as hdul:\n",
    "        Halpha = NDData(data=hdul['HA6562_FLUX'].data,\n",
    "                        uncertainty=StdDevUncertainty(hdul['HA6562_FLUX_ERR'].data),\n",
    "                        mask=np.isnan(hdul['HA6562_FLUX'].data),\n",
    "                        meta=hdul['HA6562_FLUX'].header,\n",
    "                        wcs=WCS(hdul['HA6562_FLUX'].header))\n",
    "        \n",
    "    filename = data_ext / 'WFI' / f'{name}_Rc_flux_nosky.fits'\n",
    "    with fits.open(filename) as hdul:\n",
    "\n",
    "        WFI = NDData(data=hdul[0].data,\n",
    "                     meta=hdul[0].header,\n",
    "                     wcs=WCS(hdul[0].header))\n",
    "        \n",
    "\n",
    "    reg_muse_pix, reg_muse_sky = find_sky_region(Halpha.mask.astype(int),wcs=Halpha.wcs)\n",
    "    if name in hst_sample:\n",
    "        reg_hst_pix, reg_hst_sky = find_sky_region(hst_whitelight.mask.astype(int),wcs=hst_whitelight.wcs)\n",
    "    \n",
    "    WFI_cutout = Cutout2D(WFI.data,sample_table.loc[name]['SkyCoord'],size=8*u.arcmin,wcs=WFI.wcs)\n",
    "    \n",
    "    # project from muse to hst coordinates\n",
    "    reg_muse_wfi = reg_muse_sky.to_pixel(WFI_cutout.wcs)\n",
    "    if name in hst_sample:\n",
    "        reg_hst_wfi  = reg_hst_sky.to_pixel(WFI_cutout.wcs)\n",
    "\n",
    "    ax = next(axes_iter)\n",
    "\n",
    "    # plot image\n",
    "    norm = simple_norm(WFI_cutout.data,clip=False,percent=99)\n",
    "    ax.imshow(WFI_cutout.data,norm=norm,cmap=plt.cm.gray,origin='lower')\n",
    "\n",
    "    reg_muse_wfi.plot(ax=ax,ec='tab:red',label='MUSE',lw=0.5)\n",
    "    if name in hst_sample:\n",
    "        reg_hst_wfi.plot(ax=ax,ec='tab:orange',label='HST',lw=0.5)\n",
    "    t = ax.text(0.05,0.91,name, transform=ax.transAxes,color='black',fontsize=8)\n",
    "    t.set_bbox(dict(facecolor='white', alpha=1, ec='white'))\n",
    "\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "\n",
    "for i in range(nrows*ncols-len(sample)):\n",
    "\n",
    "    # remove the empty axes at the bottom\n",
    "    ax = next(axes_iter)\n",
    "    ax.remove()\n",
    "\n",
    "plt.subplots_adjust(wspace=-0.01,hspace=0.05)\n",
    "plt.savefig(basedir/'reports'/'all_objects.pdf',dpi=600)\n",
    "plt.savefig(basedir/'reports'/'all_objects.png',dpi=600)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from astropy.nddata import Cutout2D\n",
    "from cluster.regions import find_sky_region\n",
    "\n",
    "\n",
    "ncols = 5\n",
    "nrows = int(np.ceil(len(muse_sample)/ncols))\n",
    "\n",
    "width = 1.5*two_column\n",
    "fig, axes = plt.subplots(nrows=nrows,ncols=ncols,figsize=(width,width/ncols*nrows))\n",
    "axes_iter = iter(axes.flatten())\n",
    "\n",
    "for name in sorted(muse_sample):\n",
    "    \n",
    "    print(name)\n",
    "    \n",
    "    catalogue_file = basedir/'..'/'PNLF'/'data'/'catalogues'/f'{name}_nebulae.txt'\n",
    "    catalogue = ascii.read(catalogue_file,format='fixed_width_two_line',delimiter_pad=' ',position_char='=')\n",
    "    catalogue['SkyCoord'] = SkyCoord(catalogue['RaDec'])\n",
    "    catalogue=catalogue[catalogue['type']=='PN']\n",
    "    \n",
    "    filename = data_ext / 'WFI' / f'{name}_Rc_flux_nosky.fits'\n",
    "    with fits.open(filename) as hdul:\n",
    "\n",
    "        WFI = NDData(data=hdul[0].data,\n",
    "                     meta=hdul[0].header,\n",
    "                     wcs=WCS(hdul[0].header))\n",
    "        \n",
    "    \n",
    "    WFI_cutout = Cutout2D(WFI.data,sample_table.loc[name]['SkyCoord'],size=5*u.arcmin,wcs=WFI.wcs)\n",
    "\n",
    "    ax = next(axes_iter)\n",
    "\n",
    "    # plot image\n",
    "    norm = simple_norm(WFI_cutout.data,clip=False,percent=99)\n",
    "    ax.imshow(WFI_cutout.data,norm=norm,cmap=plt.cm.gray,origin='lower')\n",
    "    \n",
    "    x,y = catalogue['SkyCoord'].to_pixel(WFI_cutout.wcs)\n",
    "    ax.scatter(x,y,marker='o',ec='tab:red',fc='none',s=1,lw=0.2)\n",
    "    \n",
    "    t = ax.text(0.05,0.91,name, transform=ax.transAxes,color='black',fontsize=8)\n",
    "    t.set_bbox(dict(facecolor='white', alpha=1, ec='white'))\n",
    "\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "\n",
    "for i in range(nrows*ncols-len(muse_sample)):\n",
    "\n",
    "    # remove the empty axes at the bottom\n",
    "    ax = next(axes_iter)\n",
    "    ax.remove()\n",
    "\n",
    "plt.subplots_adjust(wspace=-0.01,hspace=0.05)\n",
    "plt.savefig(basedir/'reports'/'all_objects_PN.pdf',dpi=600)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from astropy.nddata import Cutout2D\n",
    "from cluster.regions import find_sky_region\n",
    "\n",
    "\n",
    "ncols = 5\n",
    "nrows = int(np.ceil(len(muse_sample)/ncols))\n",
    "\n",
    "width = 1.5*two_column\n",
    "fig, axes = plt.subplots(nrows=nrows,ncols=ncols,figsize=(width,width/ncols*nrows))\n",
    "axes_iter = iter(axes.flatten())\n",
    "\n",
    "for name in sorted(muse_sample):\n",
    "    \n",
    "    print(name)\n",
    "    \n",
    "    catalogue = filter_table(nebulae,gal_name=name)\n",
    "    #catalogue['SkyCoord'] = SkyCoord(catalogue['RaDec'])\n",
    "    \n",
    "    filename = data_ext / 'WFI' / f'{name}_Rc_flux_nosky.fits'\n",
    "    with fits.open(filename) as hdul:\n",
    "        WFI = NDData(data=hdul[0].data,\n",
    "                     meta=hdul[0].header,\n",
    "                     wcs=WCS(hdul[0].header))\n",
    "        \n",
    "    \n",
    "    WFI_cutout = Cutout2D(WFI.data,sample_table.loc[name]['SkyCoord'],size=5*u.arcmin,wcs=WFI.wcs)\n",
    "\n",
    "    ax = next(axes_iter)\n",
    "\n",
    "    # plot image\n",
    "    norm = simple_norm(WFI_cutout.data,clip=False,percent=99)\n",
    "    ax.imshow(WFI_cutout.data,norm=norm,cmap=plt.cm.gray,origin='lower')\n",
    "    \n",
    "    x,y = catalogue['SkyCoord'].to_pixel(WFI_cutout.wcs)\n",
    "    ax.scatter(x,y,marker='o',ec='tab:blue',fc='none',s=1,lw=0.2)\n",
    "    \n",
    "    t = ax.text(0.05,0.91,name, transform=ax.transAxes,color='black',fontsize=8)\n",
    "    t.set_bbox(dict(facecolor='white', alpha=1, ec='white'))\n",
    "\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "\n",
    "for i in range(nrows*ncols-len(muse_sample)):\n",
    "\n",
    "    # remove the empty axes at the bottom\n",
    "    ax = next(axes_iter)\n",
    "    ax.remove()\n",
    "\n",
    "plt.subplots_adjust(wspace=-0.01,hspace=0.05)\n",
    "plt.savefig(basedir/'reports'/'all_objects_nebulae.pdf',dpi=600)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## SITELLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fig,(ax1,ax2,ax3) = plt.subplots(ncols=3,figsize=(10,4))\n",
    "\n",
    "for name,ax in zip(['NGC0628','NGC2835','NGC3351'],[ax1,ax2,ax3]):\n",
    "    with fits.open(basedir/'..'/'sitelle'/'data_v2p1'/'maps'/f'{name}_OII_map.fits') as hdul:\n",
    "        OII = hdul['OII3726_FLUX'].data\n",
    "        OII_header = hdul['OII3726_FLUX'].header\n",
    "    \n",
    "    norm = simple_norm(OII,clip=False,percent=98)\n",
    "    ax.imshow(OII,norm=norm,origin='lower',cmap=plt.cm.Greys)\n",
    "    ax.set_title(name)\n",
    "    ax.axis('off')\n",
    "    \n",
    "plt.show()   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "use [OII] line to calculate strong line and direct abundances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from cluster.metallicity import diagnostic_line_ratios\n",
    "\n",
    "with fits.open(basedir / 'data' / 'interim' / 'Nebulae_Catalogue_v2p1.fits') as hdul:\n",
    "    nebulae = Table(hdul[1].data)\n",
    "with fits.open(basedir/'data'/'interim'/'Nebulae_Catalogue_v2p1_OII.fits') as hdul:\n",
    "    OII_fluxes = Table(hdul[1].data)\n",
    "\n",
    "nebulae_with_OII = join(nebulae,OII_fluxes,keys=['gal_name','region_ID'])\n",
    "nebulae_with_OII = nebulae_with_OII[np.isin(nebulae_with_OII['gal_name'],['NGC0628','NGC2835','NGC3351','NGC4535'])]\n",
    "nebulae_with_OII = nebulae_with_OII[nebulae_with_OII['OII3726_FLUX_CORR']>0]\n",
    "\n",
    "line_ratios = diagnostic_line_ratios(nebulae_with_OII)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "compare with Figure 8 in Pilyugin+2016 (looks good if R2*=1.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from cluster.metallicity import strong_line_metallicity_R, strong_line_metallicity_S\n",
    "\n",
    "subsample = nebulae_with_OII[nebulae_with_OII['OII3726_FLUX_CORR']>10*nebulae_with_OII['OII3726_FLUX_CORR_ERR']].copy()\n",
    "print(f'{len(subsample)} objects in sample')\n",
    "\n",
    "# looks a lot better with 1.4*R2\n",
    "subsample['OH_R'] = strong_line_metallicity_R(subsample['R2'],subsample['R3'],subsample['N2'])\n",
    "subsample['OH_S'] = strong_line_metallicity_S(subsample['S2'],subsample['R3'],subsample['N2'])\n",
    "\n",
    "fig,(ax1,ax2)=plt.subplots(ncols=2,figsize=(6,3))\n",
    "\n",
    "ax1.plot([8.1,8.8],[8.1,8.8],color='black')\n",
    "ax1.plot([8.1,8.8],[8.2,8.9],color='grey',ls='--')\n",
    "ax1.plot([8.1,8.8],[8.0,8.7],color='grey',ls='--')\n",
    "ax1.scatter(subsample['OH_S'],subsample['OH_R'],s=4,c=tab10[0])\n",
    "\n",
    "ax1.set(xlim=[8.1,8.8],ylim=[8.1,8.8],\n",
    "       xlabel='12+log(O/H)$_\\mathrm{S}$',\n",
    "       ylabel='12+log(O/H)$_\\mathrm{R}$')\n",
    "ax2.hist(subsample['OH_S']-subsample['OH_R'],bins=np.linspace(-0.3,0.3,20),histtype='step',color='black')\n",
    "ax2.set(xlabel=r'log(O/H)$_\\mathrm{S}-$log(O/H)$_\\mathrm{R}$')\n",
    "#plt.savefig('12+logOH R vs S calibration.png',dpi=600)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "with direct method. This requires electron temperature and density. They have to be measured in an itterative process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from cluster.metallicity import electron_density_sulfur,\\\n",
    "                                electron_temperature_oxygen, electron_temperature_nitrogen,\\\n",
    "                                electron_temperature_sulfur, oxygen_abundance_direct\n",
    "   \n",
    "criteria = (line_ratios['OII7319_FLUX_CORR']>7*line_ratios['OII7319_FLUX_CORR_ERR']) & (line_ratios['OII3726_FLUX_CORR']>10*line_ratios['OII3726_FLUX_CORR_ERR'])\n",
    "subsample = line_ratios[criteria].copy()\n",
    "\n",
    "subsample['OH_R'] = strong_line_metallicity_R(subsample['R2'],subsample['R3'],subsample['N2'])\n",
    "subsample['OH_S'] = strong_line_metallicity_S(subsample['S2'],subsample['R3'],subsample['N2'])\n",
    "    \n",
    "# initial guess for the temperature\n",
    "subsample['t(NII)'] = electron_temperature_nitrogen(subsample['RN2'])\n",
    "subsample['t(SIII)'] = electron_temperature_sulfur(subsample['RS3'])\n",
    "subsample['n(SII)']  = electron_density_sulfur(subsample['RS2'],subsample['t(NII)'])\n",
    "\n",
    "for x in range(10):\n",
    "    subsample['t(OII)'] = electron_temperature_oxygen(subsample['RO2'],subsample['n(SII)'])\n",
    "    subsample['n(SII)'] = electron_density_sulfur(subsample['RS2'],subsample['t(OII)'])\n",
    "    print(np.nanmean(subsample['n(SII)']))\n",
    "\n",
    "subsample['OH_direct'] = oxygen_abundance_direct(subsample['R2'],subsample['R3'],subsample['t(OII)'],subsample['n(SII)'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fig,(ax1,ax2)=plt.subplots(ncols=2,figsize=(6,3))\n",
    "\n",
    "ax1.plot([8.1,8.8],[8.1,8.8],color='black')\n",
    "ax1.plot([8.1,8.8],[8.2,8.9],color='grey',ls='--')\n",
    "ax1.plot([8.1,8.8],[8.0,8.7],color='grey',ls='--')\n",
    "ax1.scatter(subsample['OH_direct'],subsample['OH_R'],s=4,c=tab10[0])\n",
    "ax1.set(xlim=[8.1,8.8],ylim=[8.1,8.8],\n",
    "       xlabel='12+log(O/H) direct',\n",
    "       ylabel='12+log(O/H)$_\\mathrm{R}$')\n",
    "ax2.hist(subsample['OH_direct']-subsample['OH_R'],bins=np.linspace(-0.3,0.3,20),histtype='step',color='black')\n",
    "ax2.set(xlabel=r'log(O/H) direct$-$log(O/H)$_\\mathrm{R}$')\n",
    "#plt.savefig('12+logOH R vs S calibration.png',dpi=600)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "compare with Figure 7 in Perez-Montero+2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots(figsize=(6,4))\n",
    "\n",
    "ax.scatter(np.log10(subsample['R23']),subsample['OH_direct'],s=4,c=subsample['logq_D91'])\n",
    "ax.set(xlim=[-0.4,1.4],ylim=[7.,9.0],\n",
    "       xlabel='log R23',\n",
    "       ylabel='12+log(O/H) direct')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots(figsize=(4,4))\n",
    "\n",
    "ax.plot([0.5,1.5],[0.5,1.5],color='black')\n",
    "ax.scatter(subsample['t(OII)'],subsample['t(NII)'],s=4,c=tab10[0])\n",
    "ax.set(xlim=[0.5,1.5],ylim=[0.5,1.5],\n",
    "       xlabel='t([OII])',\n",
    "       ylabel='t([NII])')\n",
    "#plt.savefig('12+logOH R vs S calibration.png',dpi=600)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Playground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure_dig(data,mask,label,position,factor=1,max_iter=10,size=32,plot=False):\n",
    "    '''measure the diffuse ionized gas around an HII-region'''\n",
    "    \n",
    "    cutout_mask = Cutout2D(mask.data,position,size=(size,size),mode='partial',fill_value=np.nan)\n",
    "    cutout_data = Cutout2D(data.data,position,size=(size,size),mode='partial',fill_value=np.nan)\n",
    "    \n",
    "    area_mask  = np.sum(cutout_mask.data==label)\n",
    "    input_mask = cutout_mask.data==label\n",
    "    \n",
    "    n_iter = 0\n",
    "    while True:\n",
    "        n_iter+=1\n",
    "        boundaries = find_boundaries(input_mask,mode='outer')\n",
    "        input_mask |=boundaries\n",
    "        area_boundary = np.sum(input_mask & np.isnan(cutout_mask.data)) \n",
    "        if area_boundary > factor*area_mask or n_iter>max_iter: break\n",
    "            \n",
    "    if plot:\n",
    "        fig,ax=plt.subplots(figsize=(5,5))\n",
    "        ax.imshow(cutout_mask.data,origin='lower')\n",
    "        mask = np.zeros((*cutout_mask.shape,4))\n",
    "        mask[input_mask & np.isnan(cutout_mask.data),:] = (1,0,0,0.5)\n",
    "        ax.imshow(mask,origin='lower')\n",
    "        plt.show()\n",
    "        \n",
    "    #if np.sum(boundaries & np.isnan(cutout_mask.data))==0:\n",
    "    #    print(f'no boundaries for {label}')\n",
    "    dig = cutout_data.data[input_mask & np.isnan(cutout_mask.data)]\n",
    "\n",
    "    return np.median(dig),np.mean(dig),np.sum(dig)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Old and young populations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from regions import read_ds9\n",
    "\n",
    "tmp = catalogue[catalogue['gal_name']=='NGC1365']\n",
    "\n",
    "# filter image with uncertainties\n",
    "filename = data_ext / 'HST' / 'filterImages' / f'NGC1365_uvis_f275w_exp_drc_sci.fits'\n",
    "with fits.open(filename) as hdul:\n",
    "    F275 = NDData(hdul[0].data,\n",
    "                  mask=hdul[0].data==0,\n",
    "                  meta=hdul[0].header,\n",
    "                  wcs=WCS(hdul[0].header))\n",
    "\n",
    "associations,associations_mask = read_associations(folder=data_ext/'HST',target='NGC1365',scalepc=32)\n",
    "reg_young, reg_old = read_ds9(basedir/'data'/'tmp'/'young_old.reg')\n",
    "\n",
    "# the catalogue\n",
    "young_sample = tmp[reg_young.contains(tmp['SkyCoord_asc'],wcs=associations_mask.wcs)]\n",
    "young_sample = young_sample[young_sample['age']<20]\n",
    "old_sample = tmp[reg_old.contains(tmp['SkyCoord_asc'],wcs=associations_mask.wcs)]\n",
    "old_sample = old_sample[old_sample['age']>20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the maps\n",
    "young = np.isin(associations_mask.data,associations[associations['age']<10]['assoc_ID'])\n",
    "old   = np.isin(associations_mask.data,associations[associations['age']>10]['assoc_ID'])\n",
    "\n",
    "young = young.astype(float)\n",
    "young[young==0] = np.nan\n",
    "\n",
    "old = old.astype(float)\n",
    "old[old==0] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plt.figure(figsize=(8,8))\n",
    "ax = fig.add_subplot(projection=F275.wcs)\n",
    "\n",
    "norm = simple_norm(F275.data,clip=False,percent=99)\n",
    "ax.imshow(F275.data,norm=norm,origin='lower',cmap=plt.cm.Greys,alpha=0.5)\n",
    "ax.imshow(old,vmin=0,vmax=1,cmap=plt.cm.Reds,alpha=0.8)\n",
    "ax.imshow(young,vmin=0,vmax=1,cmap=plt.cm.Blues,alpha=0.8)\n",
    "\n",
    "reg_young_pix = reg_young.to_pixel(F275.wcs)\n",
    "reg_old_pix = reg_old.to_pixel(F275.wcs)\n",
    "\n",
    "ax.add_artist(reg_young_pix.as_artist())\n",
    "ax.add_artist(reg_old_pix.as_artist())\n",
    "\n",
    "\n",
    "ax.set(xlim=[2000,5000],ylim=[3000,5000])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xlim = [0,10]\n",
    "\n",
    "\n",
    "fig,ax=plt.subplots(figsize=(single_column,single_column))\n",
    "\n",
    "sc = ax.scatter(young_sample['EBV_stars'],young_sample['EBV_balmer'],color='g',label='upper arm')\n",
    "sc = ax.scatter(old_sample['EBV_stars'],old_sample['EBV_balmer'],color='m',label='lower arm')\n",
    "ax.legend()\n",
    "ax.plot([0,1],[0,2],color='black')\n",
    "ax.plot([0,2],[0,2],color='black')\n",
    "#fig.colorbar(sc,label='age / Myr',cax=cax)\n",
    "ax.set(xlim=[0,0.7],ylim=[0,0.7],xlabel='E(B-V) stars',ylabel='E(B-V) Balmer')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "290.133px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
